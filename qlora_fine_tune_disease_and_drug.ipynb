{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2a3e9a38e1b4b159e70f168b6523381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3903a22140647e49aa7b4b72b73d74f",
              "IPY_MODEL_5b337491fb194e8fb6e57b1bc4f77ac4",
              "IPY_MODEL_8e78e4f981734812822899e7ed3535f8"
            ],
            "layout": "IPY_MODEL_9ed3dd7c6aa246bcb1d783ac28b4cbae"
          }
        },
        "f3903a22140647e49aa7b4b72b73d74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50126a864c62456c85baa1fbed52e797",
            "placeholder": "​",
            "style": "IPY_MODEL_404df12d145845ad857345f62eb20186",
            "value": "Map: 100%"
          }
        },
        "5b337491fb194e8fb6e57b1bc4f77ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0251a83ffe434c088b34ddb0057d181b",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f3cd0ebb7f8495a8139b8303d8570fb",
            "value": 1000
          }
        },
        "8e78e4f981734812822899e7ed3535f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc34c6f0c87489faedb47c1895772ac",
            "placeholder": "​",
            "style": "IPY_MODEL_3153f30f29e1440dafbb3532beed5846",
            "value": " 1000/1000 [00:00&lt;00:00, 2287.37 examples/s]"
          }
        },
        "9ed3dd7c6aa246bcb1d783ac28b4cbae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50126a864c62456c85baa1fbed52e797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "404df12d145845ad857345f62eb20186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0251a83ffe434c088b34ddb0057d181b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3cd0ebb7f8495a8139b8303d8570fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bc34c6f0c87489faedb47c1895772ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3153f30f29e1440dafbb3532beed5846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b7d1755423f41859a5e14ba0c93d09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3c1846e1e624182a48c1ccfa8ce270c",
              "IPY_MODEL_dc91c1c157094e419a941b1fc370cfb4",
              "IPY_MODEL_431a6c5cac8b4155bd4d820dc847d9a8"
            ],
            "layout": "IPY_MODEL_3bb5e602fda549eaaa8d539b8c82221d"
          }
        },
        "b3c1846e1e624182a48c1ccfa8ce270c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f9b3905182e44d4b9cd365707697f54",
            "placeholder": "​",
            "style": "IPY_MODEL_1e376c9cf0224e55862c634e8c5fe7b5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "dc91c1c157094e419a941b1fc370cfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3900d87db2b4d389d51660afde44038",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_503a036e8ed4415c8599ce162cc2a78d",
            "value": 2
          }
        },
        "431a6c5cac8b4155bd4d820dc847d9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d47bbcfa7d4fab964e2c6a8d4f7f45",
            "placeholder": "​",
            "style": "IPY_MODEL_36cf7034dee340d69273699dd8f8441f",
            "value": " 2/2 [00:04&lt;00:00,  2.11s/it]"
          }
        },
        "3bb5e602fda549eaaa8d539b8c82221d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f9b3905182e44d4b9cd365707697f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e376c9cf0224e55862c634e8c5fe7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3900d87db2b4d389d51660afde44038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "503a036e8ed4415c8599ce162cc2a78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8d47bbcfa7d4fab964e2c6a8d4f7f45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36cf7034dee340d69273699dd8f8441f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cd2317cbf9747d6909781deb6dcfc89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4be6aeb26c9740e6af2d54e8f4941fb1",
              "IPY_MODEL_aca9d3e6dac94e57b17f8e870d2018a7",
              "IPY_MODEL_d6113210846e407d856e9792b0774736"
            ],
            "layout": "IPY_MODEL_73e6a97f3d3245d992457c76a6967ab6"
          }
        },
        "4be6aeb26c9740e6af2d54e8f4941fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d30ef2820a24d9ab3e073eee20211f7",
            "placeholder": "​",
            "style": "IPY_MODEL_8f54f9e62bd740dab98e11cb2517e2fc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "aca9d3e6dac94e57b17f8e870d2018a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4514f162970049339ccdc212c75552ae",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd970a0aafab45eb97ed37f5a685dcd1",
            "value": 2
          }
        },
        "d6113210846e407d856e9792b0774736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01726754ef8a4d1ab8c5eb3d3b92af86",
            "placeholder": "​",
            "style": "IPY_MODEL_56a977547333442dbb0012cc92a503c3",
            "value": " 2/2 [00:03&lt;00:00,  1.46s/it]"
          }
        },
        "73e6a97f3d3245d992457c76a6967ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d30ef2820a24d9ab3e073eee20211f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f54f9e62bd740dab98e11cb2517e2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4514f162970049339ccdc212c75552ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd970a0aafab45eb97ed37f5a685dcd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01726754ef8a4d1ab8c5eb3d3b92af86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a977547333442dbb0012cc92a503c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Fine-Tuning LLaMA-2 with QLoRA for Disease-Drug Recommendations</h1>\n",
        "In this project, I fine-tuned the LLaMA-2 language model using QLoRA (Quantized Low-Rank Adaptation) to improve performance on a disease-drug recommendation task. Below, I explain the methodology, the QLoRA approach, and the dataset used."
      ],
      "metadata": {
        "id": "j2dHF14AriHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>1. Project Objective</h1>\n",
        "The goal of this fine-tuning task is to train a large language model (LLM) to generate accurate drug recommendations based on given diseases. The dataset is structured to include instructions, input disease names, and corresponding drug outputs."
      ],
      "metadata": {
        "id": "T4KhREAcrs3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>2. Dataset</h1>\n",
        "The dataset follows an instruction-tuning format, which is essential for fine-tuning models like LLaMA-2 to align them with specific tasks.\n",
        "\n",
        "<h2>Sample Data Structure</h2>\n",
        "\n",
        "Each data point includes:\n",
        "\n",
        "* **Instruction:** A guiding statement for the model.\n",
        "\n",
        "* **Input:** A disease-related query.\n",
        "\n",
        "* **Output:** The recommended drug.\n",
        "\n",
        "**Example Entries:**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"instruction\": \"Please specify the recommended drug for the given disease.\",\n",
        "  \"input\": \"Disease: Melanoma. What is the recommended drug?\",\n",
        "  \"output\": \"talimogene laherparepvec\"\n",
        "},\n",
        "{\n",
        "  \"instruction\": \"What is the standard drug treatment for this disease?\",\n",
        "  \"input\": \"Disease: Pharyngitis. What is the recommended drug?\",\n",
        "  \"output\": \"ampicillin\"\n",
        "},\n",
        "{\n",
        "  \"instruction\": \"Please specify the recommended drug for the given disease.\",\n",
        "  \"input\": \"Disease: Cough. What is the recommended drug?\",\n",
        "  \"output\": \"dextromethorphan / guaifenesin\"\n",
        "}\n",
        "```\n",
        "This structure allows the model to learn to generate contextually appropriate responses for disease-drug queries."
      ],
      "metadata": {
        "id": "7OKvaApZsB8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>3. What is QLoRA?</h1>\n",
        "QLoRA (Quantized Low-Rank Adaptation) is a parameter-efficient fine-tuning method that enables the fine-tuning of large language models (LLMs) on low-resource hardware without requiring the full model to be updated.\n",
        "\n",
        "<h2>QLoRA Steps:</h2>\n",
        "\n",
        "**1. 4-bit Quantization:**\n",
        "* The base model (e.g., LLaMA-2) is loaded in a 4-bit precision format using the bitsandbytes library.\n",
        "* This drastically reduces memory usage, making it feasible to fine-tune LLMs on consumer GPUs.\n",
        "\n",
        "**2. Low-Rank Adaptation (LoRA):**\n",
        "* Instead of updating all model parameters, LoRA introduces low-rank matrices to approximate the weight updates in transformer layers.\n",
        "* The rank (r) and scaling factor (a) control the LoRA updates.\n",
        "\n",
        "**3. Efficient Backpropagation:**\n",
        "* Gradients are applied only to the LoRA parameters, while the base model remains frozen."
      ],
      "metadata": {
        "id": "-tX3OMJVt9KU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>4. Fine-Tuning Workflow</h1>\n",
        "The fine-tuning process involded the following steps:\n",
        "\n",
        "<h2>Step 1: Environment Setup</h2>\n",
        "\n",
        "* **transformers:** For loading and training the model.\n",
        "\n",
        "* **peft:** For parameter efficient fine-tuning (QLoRA).\n",
        "\n",
        "* **bitsandbytes:** For 4-bit quantization.\n",
        "\n",
        "* **datasets:** For processing the dataset.\n",
        "\n",
        "* **accelerate:** For efficient distrubuted training.\n",
        "\n",
        "<h2>Step 2: Loading the Dataset</h2>\n",
        "\n",
        "The dataset was loaded in Hugging Face format and preprocessed into prompts:\n",
        "```python\n",
        "f\"### Instruction: {instruction}\\n### Input: {input}\\n### Response: {output}\"\n",
        "```\n",
        "\n",
        "<h2>Step 3: Model and QLoRA Configuration</h2>\n",
        "\n",
        "* **Model:**\n",
        "The LLaMA-2-7B model was loaded using 4-bit quantization:\n",
        "\n",
        "```python\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", load_in_4bit=True)\n",
        "````\n",
        "\n",
        "* **LoRA Configuration:**\n",
        "LoRA was applied to the attention layers (q_proj, k_proj, v_proj, o_proj)\n",
        "\n",
        "<h2>Step 4: Training</h2>\n",
        "Training was configured using TrainingArguments with:\n",
        "\n",
        "* 3 epochs\n",
        "* Batch size of 4\n",
        "* Gradient accumulation to simulate larger batch size\n",
        "* Cosine learning rate scehduler\n"
      ],
      "metadata": {
        "id": "3rwEFFZvu4X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>5. Generating Predictions</h1>\n",
        "After the fine-tuning, I tested the model with example queries to generate disease-drug recommendations:\n",
        "\n",
        "```python\n",
        "def generate_response(prompt, model, tokenizer, max_length=256):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_length=max_length, temperature=0.8, top_p=0.9)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Example query\n",
        "prompt = \"Disease: Diabetes. What is the recommended drug?\"\n",
        "response = generate_response(prompt, model, tokenizer)\n",
        "print(response)\n",
        "```\n"
      ],
      "metadata": {
        "id": "0uyzU59CxRYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>6. Results and Applications</h1>\n",
        "The fine-tuned LLaMA-2 model can now respond to disease-related queries and provide drug recommendations based on its fine-tuned knowledge.\n",
        "\n",
        "**Example Interaction:**\n",
        "* **Input:** \"Disease: Melanoma. What is the recommended drug?\"\n",
        "* **Output:** \"talimogene laherparepvec\""
      ],
      "metadata": {
        "id": "SSZtovb3xrlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>7. Key Benefits of QLoRA</h1>\n",
        "\n",
        "* **Memory Efficiency:** Using 4-bit quantization enables fine-tuning on limited hardware resources.\n",
        "* **Parameter Efficiency:** LoRA updates only a fraction of the model parameters, reducing computational cost.\n",
        "* **Domain Adaptation:** The model can specialize in a specific domain (e.g., disease-drug recommendations) with minimal effort."
      ],
      "metadata": {
        "id": "X3skuGcyyKxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project successfully fine-tuned LLaMA-2 using QLoRA for disease-drug recommendation tasks, demonstrating the ability of large language models to adapt to specialized medical datasets efficiently."
      ],
      "metadata": {
        "id": "XCNui0GzyjII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Environment Setup</h1>\n"
      ],
      "metadata": {
        "id": "Xx4LiFltxDYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "This block installs the required Python libraries to set up the environment. These libraries are essential for fine-tuning the model using QLoRA.\n",
        "\n",
        "**Key Libraries:**\n",
        "- `transformers`: For model loading and fine-tuning.\n",
        "- `peft`: For parameter-efficient fine-tuning with LoRA.\n",
        "- `bitsandbytes`: To enable 4-bit quantization of the model.\n",
        "- `accelerate`: For efficient distributed training.\n",
        "- `datasets`: To load and preprocess the dataset.\n",
        "- `trl`: For training large language models with Reinforcement Learning from Human Feedback (RLHF).\n",
        "\n",
        "**Expected Outcome:**\n",
        "The required libraries are installed successfully, and the environment is ready for model fine-tuning."
      ],
      "metadata": {
        "id": "8vKqPN6DpQap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVCJMBHch2Pr",
        "outputId": "8f828de0-dd8a-4af2-e022-bbd5357eb34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2023.10.0 which is incompatible.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers==4.36.2\n",
        "!pip install -q peft==0.7.1\n",
        "!pip install -q bitsandbytes==0.41.3\n",
        "!pip install -q accelerate==0.25.0\n",
        "!pip install -q datasets==2.15.0\n",
        "!pip install -q trl==0.7.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Login to Hugging Face</h1>"
      ],
      "metadata": {
        "id": "gJ5RULnturOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwDQ9Ff-ivGa",
        "outputId": "f0be7a08-2e71-4082-ea0c-e09d0d003438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `last-token` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `last-token`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Load Dataset</h1>"
      ],
      "metadata": {
        "id": "Ux0wX70Fy0iY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "To load and convert the dataset into a format compatible with Hugging Face tools for easy preprocessing and training.\n",
        "\n",
        "**Dataset Details:**\n",
        "- Each entry in the dataset contains three fields: `instruction`, `input`, and `output`.\n",
        "- The dataset is structured to support instruction-based fine-tuning of the LLaMA-2 model.\n",
        "\n",
        "**Steps:**\n",
        "1. Load the JSON dataset containing disease-drug mappings.\n",
        "2. Convert it into a Hugging Face `Dataset` object for seamless integration with the `transformers` library.\n",
        "\n",
        "**Expected Outcome:**\n",
        "The dataset is successfully loaded and converted into the required format, ready for further preprocessing and tokenization."
      ],
      "metadata": {
        "id": "W2lSa37apY_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import json\n",
        "\n",
        "# Load your dataset\n",
        "with open('/content/converted_dataset.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Convert to HuggingFace dataset format\n",
        "dataset = Dataset.from_dict({\n",
        "    'instruction': [item['instruction'] for item in data],\n",
        "    'input': [item['input'] for item in data],\n",
        "    'output': [item['output'] for item in data]\n",
        "})\n",
        "\n",
        "# Quantization configuration\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JLOU3xviQEI",
        "outputId": "2732eee0-f28f-4a6f-e34a-2ce6c37011a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 16,777,216 || all params: 6,755,192,832 || trainable%: 0.24836028248556738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Dataset Preporcessing</h1>"
      ],
      "metadata": {
        "id": "VFYnj46Z3rUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7jAWmVS7plIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(instruction, input_text, output):\n",
        "    return f\"\"\"### Instruction: {instruction}\n",
        "### Input: {input_text}\n",
        "### Response: {output}\"\"\"\n",
        "\n",
        "# Define prompt formatting\n",
        "def preprocess_function(examples):\n",
        "    prompts = [format_prompt(i, t, o) for i, t, o in zip(\n",
        "        examples['instruction'],\n",
        "        examples['input'],\n",
        "        examples['output']\n",
        "    )]\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\",\n",
        "    padding_side=\"right\",\n",
        "    add_eos_token=True\n",
        "    )\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"right\"\n",
        "    tokenized = tokenizer(\n",
        "        prompts,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "# Tokenize and preprocess the dataset\n",
        "tokenized_dataset = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset.column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e2a3e9a38e1b4b159e70f168b6523381",
            "f3903a22140647e49aa7b4b72b73d74f",
            "5b337491fb194e8fb6e57b1bc4f77ac4",
            "8e78e4f981734812822899e7ed3535f8",
            "9ed3dd7c6aa246bcb1d783ac28b4cbae",
            "50126a864c62456c85baa1fbed52e797",
            "404df12d145845ad857345f62eb20186",
            "0251a83ffe434c088b34ddb0057d181b",
            "2f3cd0ebb7f8495a8139b8303d8570fb",
            "3bc34c6f0c87489faedb47c1895772ac",
            "3153f30f29e1440dafbb3532beed5846"
          ]
        },
        "id": "LT8PkP1Gjba6",
        "outputId": "d8bac56b-0e2b-4d22-e27f-fb4621b36cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2a3e9a38e1b4b159e70f168b6523381"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Model and LoRA Configuration</h1>"
      ],
      "metadata": {
        "id": "T2JO88kN4Jum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "To configure and prepare the LLaMA-2 model with LoRA settings for efficient fine-tuning.\n",
        "\n",
        "**Key Components:**\n",
        "1. **Tokenization:**\n",
        "   - The tokenizer processes input text into tokens that can be fed into the model.\n",
        "2. **Model Loading:**\n",
        "   - The LLaMA-2-7b model is loaded in 4-bit precision to reduce memory usage.\n",
        "3. **LoRA Configuration:**\n",
        "   - `r`: Rank of the low-rank matrices.\n",
        "   - `lora_alpha`: Scaling factor for LoRA updates.\n",
        "   - `target_modules`: Transformer layers to which LoRA is applied.\n",
        "   - `lora_dropout`: Dropout rate to prevent overfitting.\n",
        "\n",
        "**Expected Outcome:**\n",
        "The model and tokenizer are successfully configured with 4-bit quantization and LoRA settings, enabling memory-efficient fine-tuning.\n"
      ],
      "metadata": {
        "id": "mGgmeJrEqD9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\",\n",
        "    padding_side=\"right\",\n",
        "    add_eos_token=True\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\",\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4b7d1755423f41859a5e14ba0c93d09f",
            "b3c1846e1e624182a48c1ccfa8ce270c",
            "dc91c1c157094e419a941b1fc370cfb4",
            "431a6c5cac8b4155bd4d820dc847d9a8",
            "3bb5e602fda549eaaa8d539b8c82221d",
            "2f9b3905182e44d4b9cd365707697f54",
            "1e376c9cf0224e55862c634e8c5fe7b5",
            "e3900d87db2b4d389d51660afde44038",
            "503a036e8ed4415c8599ce162cc2a78d",
            "a8d47bbcfa7d4fab964e2c6a8d4f7f45",
            "36cf7034dee340d69273699dd8f8441f"
          ]
        },
        "id": "R5WtU5L6mM6O",
        "outputId": "b218fceb-edbc-4682-b164-55e4c47f2724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b7d1755423f41859a5e14ba0c93d09f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ctlKiB96dtsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Training Arguments and Training</h1>"
      ],
      "metadata": {
        "id": "TzIzA3uA43fC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "To define training arguments and initiate the fine-tuning process.\n",
        "\n",
        "**Training Parameters:**\n",
        "- `num_train_epochs`: Number of training iterations.\n",
        "- `per_device_train_batch_size`: Batch size for each GPU.\n",
        "- `gradient_accumulation_steps`: Accumulates gradients over multiple steps to simulate larger batch sizes.\n",
        "- `learning_rate`: The rate at which model weights are updated.\n",
        "- `fp16`: Enables 16-bit floating-point precision for faster training.\n",
        "- `lr_scheduler_type`: Specifies the learning rate decay schedule.\n",
        "\n",
        "**Trainer Class:**\n",
        "The `Trainer` class automates the training process by integrating the model, dataset, and training configuration.\n",
        "\n",
        "**Expected Outcome:**\n",
        "The model is fine-tuned on the instruction-based dataset, adapting its parameters for disease-drug recommendation tasks.\n"
      ],
      "metadata": {
        "id": "k_bG2lgkhHmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./llama2-medical-finetuned\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    save_steps=100,\n",
        "    logging_steps=10,\n",
        "    max_steps=1000,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AJdKySmYj8Yh",
        "outputId": "10101041-f8fd-4326-d0b5-f8cf3c3f3e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241211_212139-hd4t03zp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ererol2002-marmara-university/huggingface/runs/hd4t03zp' target=\"_blank\">zesty-glitter-36</a></strong> to <a href='https://wandb.ai/ererol2002-marmara-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ererol2002-marmara-university/huggingface' target=\"_blank\">https://wandb.ai/ererol2002-marmara-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ererol2002-marmara-university/huggingface/runs/hd4t03zp' target=\"_blank\">https://wandb.ai/ererol2002-marmara-university/huggingface/runs/hd4t03zp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 54:31, Epoch 16/17]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.561700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.037900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.876100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.402800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.354400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.349300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.302600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.302800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.297500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.307400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.310900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.284800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.269900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.258200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.267000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.276200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.259200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.252400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.237800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.233600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.238700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.240400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.241000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.255400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.215600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.217500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.222600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.227800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.218600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.236500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.210800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.205000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.208700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.206300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.212700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.215100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.203000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.195200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.198800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.203600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.206700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.205100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.186900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.187900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.192800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.203100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.195700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.197100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.181100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.181900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.183900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.186400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.188400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.190300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.175700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.173500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.176800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.177300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.182400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.183000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.174600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.167700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.169900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.172100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.175700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.176800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.175900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.163100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.162300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.170100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.172500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.170400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.159700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.160100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.163500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.163700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.164200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.164200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.160700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.159000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.156800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.160400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.159300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.160900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.156700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.156200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.155900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.157400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.159300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.159100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.154600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.154500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.153800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.157600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.155200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.154200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1000, training_loss=0.25289148378372195, metrics={'train_runtime': 3295.8221, 'train_samples_per_second': 4.855, 'train_steps_per_second': 0.303, 'total_flos': 3.25588787134464e+17, 'train_loss': 0.25289148378372195, 'epoch': 16.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Generate Predictions</h1>"
      ],
      "metadata": {
        "id": "dhrQ6lkaiTGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "To generate predictions using the fine-tuned model for specific disease-related queries.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Tokenize the input query using the pre-trained tokenizer.\n",
        "2. Use the fine-tuned model to generate a response based on the input tokens.\n",
        "3. Decode the output tokens back into human-readable text.\n",
        "\n",
        "**Expected Outcome:**\n",
        "The model produces a relevant drug recommendation for the given disease query."
      ],
      "metadata": {
        "id": "icwKbyIXqcnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, model, tokenizer, max_length=256):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.3,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=3,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Disease: Diabetes, Type 2. What is the recommended drug?\"\n",
        "response = generate_response(prompt, model, tokenizer)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm68qSZ-z1MO",
        "outputId": "a3dc763b-298d-4db6-9f2d-a80ed94bb62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:430: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disease: Diabetes, Drug: Metformin. What is this drug used for? Please select the recommended use for metformin .\n",
            "What is the recommended dosage for diabetes?\n",
            "The recommended adult dose of metformine hydrochloride is 1 to 2 g twice daily or 1 g three times a day. For patients with severe renal impairment (creatinine clearance <30 mL/min), the recommended initial dose is 500 mg twice daily. Dosage adjustments may be necessary in clinical situations where fluid retention and/or hypoglycemia may occur. If treatment with metformina hydroclorida results in hypogliestemia, increase the dose by not more than 5 mg at a time until a satisfactory response is obtained. If after a satisfactorily adequate trial of metormina hydrochlora it is still necessary to administer insulin, consider using rapid acting insulins (e.g., regular).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Save and Load Model</h1>"
      ],
      "metadata": {
        "id": "rH1r86cqPVXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "To save the fine-tuned model and tokenizer for future use and reload them when needed.\n",
        "\n",
        "**Steps:**\n",
        "1. Save the model and tokenizer to the specified directory.\n",
        "2. Reload them later for inference or further fine-tuning.\n",
        "\n",
        "**Expected Outcome:**\n",
        "The fine-tuned model and tokenizer are successfully saved and can be reloaded without loss of functionality.\n"
      ],
      "metadata": {
        "id": "Csb1XV4SqgHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_and_tokenizer(model, tokenizer, save_path):\n",
        "    # Model kaydetme\n",
        "    model.save_pretrained(save_path + \"/model\")\n",
        "    # Tokenizer kaydetme\n",
        "    tokenizer.save_pretrained(save_path + \"/tokenizer\")\n",
        "\n",
        "def load_model_and_tokenizer(load_path):\n",
        "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(load_path + \"/model\")\n",
        "    model = model.cuda()\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(load_path + \"/tokenizer\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "save_path = \"/home/user/saved_model\"\n",
        "save_model_and_tokenizer(model, tokenizer, save_path)\n",
        "\n",
        "model, tokenizer = load_model_and_tokenizer(save_path)\n",
        "\n",
        "prompt = \"Disease: Diabetes, Drug: Metformin. What is this drug used for?\"\n",
        "response = generate_response(prompt, model, tokenizer)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "4cd2317cbf9747d6909781deb6dcfc89",
            "4be6aeb26c9740e6af2d54e8f4941fb1",
            "aca9d3e6dac94e57b17f8e870d2018a7",
            "d6113210846e407d856e9792b0774736",
            "73e6a97f3d3245d992457c76a6967ab6",
            "8d30ef2820a24d9ab3e073eee20211f7",
            "8f54f9e62bd740dab98e11cb2517e2fc",
            "4514f162970049339ccdc212c75552ae",
            "bd970a0aafab45eb97ed37f5a685dcd1",
            "01726754ef8a4d1ab8c5eb3d3b92af86",
            "56a977547333442dbb0012cc92a503c3"
          ]
        },
        "id": "bY64WNiy6Adn",
        "outputId": "50433e59-8735-499c-8b2d-336bc54319b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cd2317cbf9747d6909781deb6dcfc89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disease: Diabetes, Drug: Metformin. What is this drug used for? Please select the recommended condition for which\n",
            "What is this medication prescribed for? please select the appropriate disease. what is the recommended drug? metformin...\n",
            "Which of the following drugs would be most appropriate to treat diabetic ketoacidosis? a. insulin b. glucose c....\n",
            "What are the standard drugs used to treat type 2 diabetes (non-insulin)? please list all relevant drugs. what ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Save Configuration</h1>"
      ],
      "metadata": {
        "id": "G40SmJN6Pc5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_full_model(model, tokenizer, config, save_path):\n",
        "    model.save_pretrained(save_path + \"/model\")\n",
        "    tokenizer.save_pretrained(save_path + \"/tokenizer\")\n",
        "    config.save_pretrained(save_path + \"/config\")\n",
        "\n",
        "def load_full_model(load_path):\n",
        "    from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
        "\n",
        "    config = AutoConfig.from_pretrained(load_path + \"/config\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(load_path + \"/model\", config=config)\n",
        "    model = model.cuda()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(load_path + \"/tokenizer\")\n",
        "\n",
        "    return model, tokenizer, config"
      ],
      "metadata": {
        "id": "CZ8qHn7D6JNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Google Drive Integration</h1>"
      ],
      "metadata": {
        "id": "bOwm11q6PkLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/saved_model\"  # Drive'da kaydetmek istediğiniz konum\n",
        "save_model_and_tokenizer(model, tokenizer, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLEuUASj6J4G",
        "outputId": "b70ba956-1494-45d0-fd5b-2423939948b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}